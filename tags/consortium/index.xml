<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>consortium on Consortium for Python Data API Standards</title>
    <link>https://data-apis.org/tags/consortium/</link>
    <description>Recent content in consortium on Consortium for Python Data API Standards</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Apr 2024 08:00:00 +0000</lastBuildDate><atom:link href="https://data-apis.org/tags/consortium/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2023 release of the Array API Standard</title>
      <link>https://data-apis.org/blog/array_api_v2023_release/</link>
      <pubDate>Mon, 08 Apr 2024 08:00:00 +0000</pubDate>
      
      <guid>https://data-apis.org/blog/array_api_v2023_release/</guid>
      <description>Another year, another revision of the Array API Standard! We&amp;rsquo;re proud to announce the release of the 2023 revision of the Array API Standard. As was the case for 2022 revision, this release required extensive discussion and collaboration among array libraries and their downstream stakeholders as we continued reaching consensus on unified API design and behavior. We&amp;rsquo;re particularly excited to share that this year marked a significant milestone in our efforts to facilitate array interoperation within the PyData ecosystem, as we witnessed accelerated adoption of the standard, especially among downstream libraries, such as SciPy] and scikit-learn.</description>
    </item>
    
    <item>
      <title>2022 release of the Array API Standard</title>
      <link>https://data-apis.org/blog/array_api_v2022_release/</link>
      <pubDate>Wed, 01 Mar 2023 08:00:00 +0000</pubDate>
      
      <guid>https://data-apis.org/blog/array_api_v2022_release/</guid>
      <description>Today marks another significant milestone for the Consortium for Python Data API Standards. We&amp;rsquo;re excited to announce the release of the 2022 revision of the Array API Standard. This release is a culmination of extensive discussion and coordination among array libraries to build on the initial 2021 release of the Array API Standard and to continue reaching consensus on unified API design and behavior among array libraries within the PyData ecosystem.</description>
    </item>
    
    <item>
      <title>First release of the Array API Standard</title>
      <link>https://data-apis.org/blog/array_api_standard_release/</link>
      <pubDate>Tue, 10 Nov 2020 08:00:00 +0000</pubDate>
      
      <guid>https://data-apis.org/blog/array_api_standard_release/</guid>
      <description>Array and tensor libraries - from NumPy, TensorFlow and PyTorch to Dask, JAX, MXNet and beyond - could benefit greatly from a uniform API for creating and working with multi-dimensional arrays (a.k.a tensors), as we discussed in our previous blog post. Today we&amp;rsquo;re pleased to announce a first version of our array API standard (document, repo) for review by the wider community. Getting to this point took slightly longer than we had initially announced because, well, it&amp;rsquo;s 2020 and hence nothing quite goes according to plan.</description>
    </item>
    
    <item>
      <title>Announcing the Consortium for Python Data API Standards</title>
      <link>https://data-apis.org/blog/announcing_the_consortium/</link>
      <pubDate>Mon, 17 Aug 2020 08:00:00 +0000</pubDate>
      
      <guid>https://data-apis.org/blog/announcing_the_consortium/</guid>
      <description>Over the past few years, Python has exploded in popularity for data science, machine learning, deep learning and numerical computing. New frameworks pushing forward the state of the art in these fields are appearing every year. One unintended consequence of all this activity and creativity has been fragmentation in the fundamental building blocks - multidimensional array (tensor) and dataframe libraries - that underpin the whole Python data ecosystem. For example, arrays are fragmented between Tensorflow, PyTorch, NumPy, CuPy, MXNet, Xarray, Dask, and others.</description>
    </item>
    
    <item>
      <title>Want to super-charge your library by writing dataframe-agnostic code? We&#39;d love to hear from you</title>
      <link>https://data-apis.org/blog/dataframe_standard_rfc/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://data-apis.org/blog/dataframe_standard_rfc/</guid>
      <description>Tired of getting lost in if-then statements when dealing with API differences between dataframe libraries? Would you like to be able to write your code once, have it work with all major dataframe libraries, and be done? Let&amp;rsquo;s learn about an initiative which will enable you to write cross-dataframe code - no special-casing nor data conversions required!
Why would I want this anyway? Say you want to write a function which selects rows of a dataframe based on the z-score of a given column, and you want it to work with any dataframe library.</description>
    </item>
    
    <item>
      <title>Towards dataframe interoperability</title>
      <link>https://data-apis.org/blog/dataframe_protocol_rfc/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-apis.org/blog/dataframe_protocol_rfc/</guid>
      <description>In the PyData ecosystem we have a large number of dataframe libraries as of today, each with their own strengths and weaknesses. Pandas is the most popular library today. Other libraries offer significant capabilities beyond what it provides though - impressive performance gains for Vaex (CPU) and cuDF (GPU), distributed dataframes for Modin and Dask, or leveraging Spark as an execution engine for Koalas. For downstream library authors, it would be powerful to be able to work with all these libraries.</description>
    </item>
    
  </channel>
</rss>
